
課程：NCHU 114 碩級機器學習專題
題目：機器學習商品自動化分類 - 以大買家電商為例
報告時長：約 7 分鐘（預期 13-15 頁）

=== 全局要求 ===

【標題格式】
- 直接陳述步驟或目的，無修飾性語言
- 使用數據驅動的表述（例：「1080+ 超參數組合搜索結果」而非「超參數優化」）
- 期中報告已涵蓋的核心目的可省略詳述

【視覺資源】
- 優先使用來源中的 PNG 圖表（model_comparison.png、confusion_matrix.png、training_history.png 等）
- 若內容描述需圖示，在對應段落標註「[插入相關 PNG]」

【開發背景參考】
- 開發環境：Windows 11 WSL2、AMD Ryzen 7 9800X3D、NVIDIA RTX 5070（Blackwell）
- 主要技術挑戰與解決方案記錄於 DEV-LOG

---

## 投影片結構與內容規範

### 【第 1 頁】標題頁
標題：機器學習商品自動化分類
副標題：以大買家電商為例
信息：姓名 "施宏勲" 學號 "5114029040"

---

### 【第 2 頁】研究目的（言簡意賅版）
- 背景：電商平台商品分類任務
- 挑戰：文本說明多為圖片，文字信息不完整（僅含產地、工廠、成分）
- 解決方案：融合視覺與文本特徵的多模態分類系統

---

### 【第 3 頁】資料收集
- 爬蟲平台：SaveSafe(大買家) 電商平台
- 收集欄位：品牌、商品名、圖片 URL、描述
- 數據規模：[補充具體商品數量及類別數]
- 發現：描述文本中產地、工廠、成分佔比低，多為圖片說明 → 促使多加圖像特徵

---

### 【第 4 頁】資料前處理
步驟流程：
1. 移除售罄商品（圖片 URL 無效）
2. 標籤編碼：8 個商品類別對應整數標籤
3. 訓練/測試集劃分：80/20（Stratified K-Fold 確保類別均衡）
4. 最終清洗資料集規模

---

### 【第 5-6 頁】圖像特徵工程

【標題】圖像特徵提取三大方法

**RGB 色彩直方圖**
- 定義：將圖像分解為紅、綠、藍三通道，各通道獨立計算 32 個 bin 的像素分佈
- 作用：捕捉商品主色調與整體顏色組成，區分不同食品外觀（如罐頭顏色、餅乾色澤）
- 輸出維度：32 × 3 = 96 維

**HSV 直方圖**
- 定義：色調（Hue）、飽和度（Saturation）、亮度（Value）各使用 16 個 bin 獨立統計
- 優勢：對光照變化魯棒，更符合人眼色彩感知，適應不同拍照環境
- 應用：區分相似產品的色差與光照差異
- 輸出維度：16 × 3 = 48 維

**HOG（梯度方向直方圖）**
- 定義：計算圖像梯度方向分佈，採用 pixels_per_cell=(100,100)、cells_per_block=(2,2)、9 個方向 bin
- 作用：偵測商品形狀、邊界輪廓、紋理特徵（如米粒紋理、餅乾表面凹凸）
- 應用於 500×500 圖像：產生 5×5 cells 網格，(5-2+1)×(5-2+1)=16 個 blocks，每個 block 2×2×9=36 特徵
- 輸出維度：4 × 4 × 9 × 4 = 576 維
- 處理：StandardScaler 標準化至均值 0、方差 1

**特徵合併**
- 總圖像特徵維度：RGB(96) + HSV(48) + HOG(576) = **720 維**

[插入圖像特徵對比圖 - 如有 PNG]

---

### 【第 7 頁】文本特徵工程

【TF-IDF 向量化配置】

**預處理**
- 特徵來源 1：品牌 + 商品名稱 → max_features 設定為 2296 (經 3-fold 交叉驗證調優)
- 特徵來源 2：商品描述文本 → max_features 設定為 2769

**超參數設定**
- N-gram 範圍：1-3 元組（unigram、bigram、trigram 混合）
- min_df：3（出現少於 3 次的詞彙過濾）
- max_df：0.8（出現在超過 80% 文件的詞彙過濾，移除通用詞）
- sublinear_tf：True（頻率以 1+log(tf) 縮放，減弱高頻詞彙影響）

**調優過程**
- 方法：3-fold Stratified K-Fold 交叉驗證
- 評估模型：Logistic Regression (max_iter=500)
- 目標：找出品牌+名稱及描述各自的最優 max_features 組合

**合併特徵**
- 品牌+名稱 TF-IDF：2296 維
- 描述 TF-IDF：2769 維
- 合計文本特徵：5065 維

---

### 【第 8 頁】傳統機器學習訓練

【模型選擇與訓練策略】

**模型**
- Random Forest：集成多棵決策樹，天然處理非線性關係
- Logistic Regression：基準模型，用於特徵重要性分析

**數據平衡**
- 問題：原始資料類別分佈不均（導致模型偏向多數類）
- 解決方案：SMOTE 過採樣
  - 機制：在少數類樣本周圍生成合成樣本
  - 參數：k_neighbors=3（取 3 個最近鄰居）
  - **應用位置**：僅在訓練集，測試集保持原始分佈（防止資料洩漏）

**超參數優化**
- 方法：RandomizedSearchCV（隨機搜索）
- 搜索空間：Random Forest 的 n_estimators、max_depth、min_samples_split 等
- 交叉驗證：3-fold Stratified K-Fold

**評估指標**
- 準確率、精準度、召回率、F1 分數
- 混淆矩陣視覺化

---

### 【第 9 頁】神經網路訓練 - 架構與設計

【網路架構（基於 84.75% 基線改進）】

```
輸入特徵 (5786 維)
    ↓
Dense(512) + BatchNorm + ReLU + Dropout(0.4)
    ↓
Dense(256) + BatchNorm + ReLU + Dropout(0.35)
    ↓
Dense(128) + BatchNorm + ReLU + Dropout(0.3)
    ↓
Dense(64)  + BatchNorm + ReLU + Dropout(0.25)
    ↓
Dense(8)   + Softmax（輸出層）
```

**輸入特徵組成**（總 5786 維）
- 品牌+名稱 TF-IDF：2296 維
- 描述 TF-IDF：2769 維
- 圖像特徵（720 維）
- 價格特徵（1 維）

**Batch Normalization 設計目的**
- 位置：每個 Dense 層之後、激活函數之前
- 作用：
  1. 穩定訓練：將輸入正規化至均值 0、方差 1，避免梯度爆炸/消失
  2. 提升收斂速度：允許使用更高的學習率
  3. 正則化效應：減少對初始化的敏感性，無需過多 Dropout
  4. 減低內部 Covariate Shift：每層獨立適應數據分佈

**Dropout 配置（依層遞減）**
- Dense(512) 後：Dropout(0.4) - 丟棄 40% 神經元，最強正則化
- Dense(256) 後：Dropout(0.35)
- Dense(128) 後：Dropout(0.3)
- Dense(64) 後：Dropout(0.25) - 最弱，靠近輸出層

[插入 PNG：網路架構圖（若有）]

---

### 【第 10 頁】神經網路訓練 - 超參數搜索

【大規模 Grid Search 實驗】

**搜索空間**
- Learning Rate：12 個候選值（0.00005 至 0.0004）
- Batch Size：9 個候選值（16, 18, 20, 22, 24, 26, 28, 32, 48）
- Dropout Config：10 個預定義配置組合
- **總計組合數**：1080 組超參數組合

**訓練策略**
- SMOTE 過採樣（訓練集）：k_neighbors=3，**防止驗證集污染**
  - 流程：先劃分訓練/驗證集 (80/20) → 只在訓練集執行 SMOTE → 驗證集保持原始分佈
- Early Stopping（驗證損失）：patience=10 epochs，min_delta=0.001
- Learning Rate Scheduling：ReduceLROnPlateau（factor=0.5, patience=5, min_lr=1e-6）
- 損失函數：Categorical Crossentropy
- 優化器：Adam
- 最大 Epoch：100

**Seed Mining 技術**
- 尋找穩定的隨機種子，確保不同運行的結果可重現
- 固定 Seed：821407（經測試達 85.16% 驗證準確率 + Label Smoothing=0.1）
- 目的：消除隨機性帶來的準確率波動

---

### 【第 11 頁】RTX 5070 訓練挑戰與解決方案

【硬體環境**
- 顯示卡：NVIDIA RTX 5070（Blackwell 架構）
- 驅動程式版本：591.44
- CUDA：13.1
- 框架：Keras 3 + PyTorch 後端

【遇到的主要問題與解決**

1. **稀疏矩陣相容性問題**
   - 錯誤：`InvalidArgumentError: TensorFlow Sparse Matrix` 操作不支援
   - 症狀：TF-IDF 特徵轉稀疏格式導致訓練崩潰
   - 解決：`.toarray().astype(float32)` 轉換為密集矩陣

2. **驗證集分割相容性**
   - 錯誤：`ValueError: validation_split is only supported for Tensors or NumPy arrays`
   - 原因：Scipy 稀疏矩陣不支援 validation_split 參數
   - 解決：改用 `sklearn.model_selection.train_test_split` 手動劃分 80/20

3. **Keras PyTorch 後端編譯問題**
   - 症狀：jit_compile=True 在 PyTorch 後端編譯失敗
   - 解決：設定 `jit_compile=False`

4. **多進程資料加載衝突**
   - 錯誤：`Keras fit() 中 workers>0 導致多進程衝突`
   - 原因：WSL2 + GPU 組合下多進程工作者相容性問題
   - 解決：使用 `workers=0, use_multiprocessing=False`

5. **Label Smoothing 與過度自信**
   - 觀察：基線 Seed Mining（無平滑）達 84.75%，但驗證損失高達 0.5709，表示過度自信
   - 改進：使用 Label Smoothing=0.1，達 85.16% 準確率，驗證損失降至 0.8536
   - 作用：將硬標籤（0/1）轉換為軟目標（如 0.1/0.9），增強模型魯棒性

【訓練耗時統計】
- 單次訓練時長：[補充平均 epoch 耗時]
- Grid Search 全程耗時：[補充總時長]
- 平均每組超參數耗時：[計算值]

---

### 【第 12 頁】集成學習方法

【模型組合】
- Component 1：Random Forest（傳統機器學習）
- Component 2：Keras Neural Network（深度學習）

【集成策略 1：加權投票（Weighted Voting）】
- RF 投票權重：0.76 (76%)
- NN 投票權重：0.24 (24%)
- 機制：合併兩模型的預測概率，按權重平均後取 argmax
- 結果準確率：[補充集成後準確率]

【集成策略 2：堆疊回歸（Stacking）】
- 第一層：RF 與 NN 各自產出預測概率（8 維向量）
- 元模型：Logistic Regression（以 RF+NN 概率為輸入特徵）
- 結果：
  - 傳統 ML（RF+LR）單模型：82.63%
  - Neural Network 單模型：83.72%
  - Stacking 集成：[補充堆疊後準確率]

---

### 【第 13 頁】模型準確率比較

【模型性能排名】

| 模型                      | 準確率 | 訓練時間 |
| ------------------------- | ------ | -------- |
| Keras Grid Search Best    | [值]%  | [時間]   |
| Keras 基線（Seed 821407） | 85.16% | [時間]   |
| Ensemble（Stacking）      | [值]%  | [時間]   |
| Random Forest             | [值]%  | [時間]   |
| Logistic Regression       | [值]%  | [時間]   |

【關鍵對比】
- 準確率 vs 訓練時間權衡：散佈圖展示效率邊界
- 最佳模型選擇依據：綜合準確率、穩定性（Seed Mining 驗證）、泛化能力
- 模型複雜度分析

[使用 PNG：model_comparison.png / performance_tradeoff.png]

---

### 【第 14 頁】查表法基線（Baseline）與對比

【方法原理】
- 預定義規則表：8 個類別各配置 10-30 個關鍵詞
- 分類邏輯：逐詞匹配品牌+商品名+描述，計算匹配分數
- 決策規則：取分數最高的類別；若無任何詞彙命中，則標為「未分類」

【準確率統計】
- 未分類比例：[%]（無法自動分類的商品比例）
- 已分類準確率：[%]（成功匹配的商品中的準確率）
- 整體準確率：[%]（包含未分類視為錯誤）

【機器學習 vs 查表法對比**
- 查表法優點：完全可解釋、無需訓練、推理瞬間
- 查表法局限：覆蓋率低、無法泛化至新商品、維護複雜
- ML 優勢：自動特徵學習、泛化能力強、可應對新數據
- 性能提升：ML 方法相比查表法提升 [N%] 準確率

[使用 PNG：lookup_confusion_matrix.png]

---

### 【第 15 頁】未來改進方向

【文本特徵升級】
- BERT / RoBERTa 預訓練語言模型：
  • 取代 TF-IDF，利用上下文語義信息
  • 捕捉商品描述中的潛在意圖（例：「營養」vs「飽足感」的語義差異）
  • 預期提升：+3~5% 準確率（基於商品分類任務的文獻基準）

【圖像特徵升級】
- Vision Transformer (ViT) / DeiT 架構：
  • 取代 HOG + 直方圖，使用 Transformer 提取高階視覺特徵
  • 優勢：更好的長距離依賴建模、對物體位置不敏感
  • ResNet50 / EfficientNet 作為 backbone 的備選
  • 預期提升：+2~4% 準確率

【多模態融合深化】
- 聯合訓練：BERT 文本編碼器 + ViT 圖像編碼器，透過共享瓶頸層融合
- Cross-Modal Attention：文本與圖像間的交叉注意力機制
- 預期準確率目標：≥ 88%

[不涉及應用層面討論]

---

### 【第 16 頁】結論與技術總結

【核心發現】
1. 多模態特徵融合優於單模態（視覺+文本 > 視覺或文本單獨）
2. Batch Normalization 與 Dropout 配合為深度模型的穩定性關鍵
3. 大規模超參數搜索（1080 組合）發現了最優配置，並透過 Seed Mining 確保穩定性

【選定最佳模型】
- Keras 神經網路（Seed 821407）+ Label Smoothing
- 準確率：85.16%（驗證集）
- 選擇原因：泛化能力強、單模型穩定性高（Seed Mining 驗證）、易於部署

【技術創新點】
- Seed Mining 技術確保訓練穩定性與可重現性
- Label Smoothing（0.1）應對過度自信問題
- SMOTE 資料洩漏修正（訓練集過採樣，驗證/測試集保持原始分佈）
- RTX 5070 Blackwell 架構的多項相容性優化

【限制與展望**
- 目前限制：查表法相對準確率低、預訓練模型未採用、圖像特徵仍用傳統 HOG
- 發展方向：BERT + ViT 多模態預訓練架構
- 預期成果：將準確率提升至 88%+

---

## 生成完成後的檢查清單

✅ 投影片頁數：13-16 頁（約 7 分鐘報告時長）
✅ 所有圖表使用來源中的 PNG
✅ 圖像特徵維度正確：RGB 96 + HSV 48 + HOG 576 = 720 維（已修正）
✅ Grid Search 1080 超參數組合詳細說明
✅ RTX 5070 遇到的 5 大問題與解決方案完整記錄
✅ BatchNorm 設計目的與層數配置清晰
✅ SMOTE 資料洩漏修正說明（訓練集過採樣，驗證集保持原始分佈）
✅ Seed Mining（Seed 821407）與 Label Smoothing（0.1）機制說明
✅ 未來展望專注準確度改進（BERT、ViT），不涉及應用
✅ 每頁內容控制在 30-40 秒講述時間

---

## 補充信息

【需手動補充的數值】
- 第 3 頁：商品總數、類別數
- 第 10 頁、第 13 頁：各模型的具體準確率數值
- 第 10-11 頁：Grid Search 全程耗時、平均每組耗時
- 第 12 頁：集成模型的最終準確率
- 第 14 頁：查表法的準確率統計（未分類比例、已分類準確率、整體準確率）

【引用圖表列表（優先次序）】
1. model_comparison.png （各模型準確率對比）
2. performance_tradeoff.png （準確率 vs 訓練時間散佈圖）
3. kerasbesttraininghistory.png （訓練/驗證曲線）
4. kerasbestconfusionmatrix.png （混淆矩陣）
5. lookup_confusion_matrix.png （查表法混淆矩陣）
6. 網路架構圖（需生成）


題目：機器學習商品自動化分類-以大買家電商為例；報告時長：約 7 分鐘（預期 13-15 頁）。全局要求：標題直陳步驟/目的，無修飾；使用數據驅動表述；優先用 PNG；背景：WSL2/RTX 5070/Keras3+PyTorch。投影片結構：【第 1 頁】標題（標題/副標題/施宏勲/5114029040）；【第 2 頁】研究目的（背景/挑戰/解決方案）；【第 3 頁】資料收集（爬蟲爬取大買家電商/8 大分類 32 子類別；大類：(1)米油罐頭泡麵[米/五穀/濃湯、油/調味料、泡麵/麵條、罐頭調理包] (2)餅乾零食飲料[休閒零嘴、美味餅乾、糖果/巧克力、飲料] (3)奶粉養生保健[養生保健/常備品、奶粉/穀麥片、特色茶品、咖啡/可可] (4)沐浴開架保養[沐浴乳香皂、美髮造型、口腔清潔、臉部清潔、開架/身體保養] (5)餐廚衛浴居家[鍋具/飲水/廚房、掃除用具/照明/五金、傢飾/收納/衛浴、寵物/園藝] (6)日用清潔用品[衛生紙/濕巾、衣物清潔、居家清潔、衛生棉/護墊、成人/嬰兒紙尿褲] (7)家電/3C配件[廚房家電、季節家電、生活家電、3C/電腦周邊/OA] (8)文具休閒服飾[文具/辦公用品、汽機車百貨、休閒/運動、服飾/配件]；爬蟲欄位：brand/name/price/image_url/description；數據規模[補充商品總數]；發現：描述多圖少文字促進多模態）；【第 4 頁】資料前處理（移除售罄/label encoding 8 大類→整數 0-7/80-20 stratified split/最終規模[補充]）；【第 5-6 頁】圖像特徵工程（RGB 直方圖 32bins×3=96 維捕捉主色調；HSV 直方圖 16bins×3=48 維；HOG pixels_per_cell(100,100) cells_per_block(2,2) 9 方向=576 維捕捉形狀紋理；合計 720 維；StandardScaler 標準化；[插入 PNG]）；【第 7 頁】文本特徵工程（TF-IDF：brand+name max_features=2296、description max_features=2769、ngram 1-3、max_df=0.8、sublinear_tf=True、3-fold 交叉驗證調優；合計文本 5065 維）；【第 8 頁】傳統 ML 訓練（Random Forest+LR；SMOTE k=3 僅訓練集防資料洩漏；RandomizedSearchCV 超參數優化；3-fold Stratified K-Fold；評估指標：準確率/精準度/召回率/F1/混淆矩陣）；【第 9 頁】神經網路架構（基於 84.75% 基線；輸入 5786=2296+2769+720+1；Dense(512)+BatchNorm+ReLU+Dropout(0.4)→Dense(256)+BatchNorm+ReLU+Dropout(0.35)→Dense(128)+BatchNorm+ReLU+Dropout(0.3)→Dense(64)+BatchNorm+ReLU+Dropout(0.25)→Dense(8)+Softmax；BatchNorm 設計目的：穩定訓練/提升收斂/正則化/減低 Covariate Shift；Dropout 遞減配置；[插入架構圖 PNG]）；【第 10 頁】超參數搜索（Grid Search 1080 組：lr 12 值(0.00005-0.0004)×bs 9 值(16-48)×dropout 10 組=1080；訓練策略：SMOTE(訓練集)k_neighbors=3、先分驗證集再 SMOTE 防污染、Early Stopping patience=10 min_delta=0.001、ReduceLROnPlateau factor=0.5 patience=5、Adam、Categorical Crossentropy、最大 100 epoch、無 Label Smoothing；Seed Mining 技術穩定隨機性；固定 Seed 821407 達 84.75% 驗證準確率；訓練耗時統計[補充]）；【第 11 頁】RTX 5070 訓練挑戰（硬體：RTX 5070 Blackwell/驅動 591.44/CUDA 13.1/Keras3+PyTorch；問題 1：稀疏矩陣相容性→.toarray().astype(float32) 轉密集；問題 2：validation_split 限制→train_test_split 手動劃分；問題 3：jit_compile=True 失敗→設 jit_compile=False；問題 4：Label Smoothing 實驗→值 0.1 導致準確率下降至 77%、無 Label Smoothing 保持 84.75%→決定不採用；耗時統計 3 分鐘）；【第 12 頁】集成學習（組件：RF+Keras NN；加權投票：RF 0.76+NN 0.24、合併概率按權重平均取 argmax、結果[補充]；Stacking：第一層 RF+NN 產 8 維概率、元模型 LR、結果[補充]；對比：RF+LR 82.63% vs NN 84.75% vs Stacking[補充]%）；【第 13 頁】模型準確率比較（表格：Keras 基線 Seed 821407 84.75%/3.4分鐘、Random Forest 80.03%/2.1秒、Logistic Regression 73.6%/14秒；對比：準確率 vs 訓練時間權衡/複雜度分析/[使用 PNG：model_comparison.png 與 performance_tradeoff.png]）；【第 14 頁】查表法基線（方法：8 大類各 10-30 關鍵詞、逐詞匹配品牌+商品名+描述、計分取 argmax；統計：未分類 3611 筆、已分類準確率 63%、整體準確率 32%；對比：查表優點可解釋/無訓練/推理快、局限覆蓋率低/無泛化/維護複雜；ML 優勢自動特徵/泛化強/適應新數據、性能提升 ML vs 查表法+50%；[使用 PNG：lookup_confusion_matrix.png]）；【第 15 頁】未來改進（文本升級：BERT/RoBERTa 取代 TF-IDF、上下文語義、預期+3~5%；圖像升級：ViT/DeiT/ResNet50/EfficientNet 取代 HOG+直方圖、長距離依賴/位置不敏感、預期+2~4%；多模態融合：聯合訓練 BERT 編碼器+ViT 編碼器、交叉注意力；不涉及應用層面）；【第 16 頁】結論（核心發現：多模態>單模態、BatchNorm+Dropout 穩定性、1080 組搜索發現最優；選定：Keras Seed 821407 無 Label Smoothing 84.75% 驗證準確率；創新點：Seed Mining 穩定可重現、Label Smoothing 實驗發現過度正則化反而降準確率、SMOTE 資料洩漏修正、RTX 5070 相容性優化；限制與展望：查表法準確率低、預訓練模型未採用、傳統 HOG 圖像→BERT+ViT 預訓練→準確率 88%+）。檢查清單：✅ 頁數 13-16 頁約 7 分鐘、✅ 所有圖表用 PNG、✅ 圖像特徵 720=96+48+576 維、✅ Grid Search 1080 組完整說明、✅ RTX 5070 五大問題解決方案、✅ BatchNorm 設計目的與層數、✅ SMOTE 資料洩漏修正（訓練集過採樣驗證集原始）、✅ Seed Mining Seed 821407 無 Label Smoothing 機制、✅ Label Smoothing 實驗失敗(77%)記錄、✅ 8 大分類 32 子類別詳列、✅ 未來展望專注準確度 BERT+ViT 無應用、✅ 每頁 30-40 秒。需補充數值：第 3 頁商品總數、第 4 頁最終規模、第 10/13 頁各模型準確率、第 10-11 頁 Grid Search 耗時、第 12 頁集成準確率。引用 PNG 優先次序：1. model_comparison.png、2. performance_tradeoff.png、3. keras_best_training_history.png、4. keras_best_confusion_matrix.png、5. lookup_confusion_matrix.png、6. 網路架構圖。


【需手動補充的數值】
- 第 3 頁：商品總數、類別數
- 第 10 頁、第 13 頁：各模型的具體準確率數值
- 第 10-11 頁：Grid Search 全程耗時、平均每組耗時
- 第 12 頁：集成模型的最終準確率
- 第 14 頁：查表法的準確率統計（未分類比例、已分類準確率、整體準確率）

【引用圖表列表（優先次序）】
1. model_comparison.png （各模型準確率對比）
2. performance_tradeoff.png （準確率 vs 訓練時間散佈圖）
3. kerasbesttraininghistory.png （訓練/驗證曲線）
4. kerasbestconfusionmatrix.png （混淆矩陣）
5. lookup_confusion_matrix.png （查表法混淆矩陣）
6. 網路架構圖（需生成）
